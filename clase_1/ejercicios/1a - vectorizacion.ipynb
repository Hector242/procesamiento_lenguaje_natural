{"cells":[{"attachments":{},"cell_type":"markdown","metadata":{"id":"Ue5hxxkdAQJg"},"source":["<img src=\"https://github.com/FIUBA-Posgrado-Inteligencia-Artificial/procesamiento_lenguaje_natural/raw/main/logoFIUBA.jpg\" width=\"500\" align=\"center\">\n","\n","\n","# Procesamiento de lenguaje natural\n","## Vectorización\n"]},{"cell_type":"code","execution_count":2,"metadata":{"id":"kCED1hh-Ioyf"},"outputs":[],"source":["import numpy as np"]},{"cell_type":"code","execution_count":3,"metadata":{"id":"PUbfVnzIIoMj"},"outputs":[],"source":["def cosine_similarity(a, b):\n","    return np.dot(a, b) / (np.linalg.norm(a) * (np.linalg.norm(b)))"]},{"cell_type":"markdown","metadata":{"id":"DMOa4JPSCJ29"},"source":["### Datos"]},{"cell_type":"code","execution_count":4,"metadata":{"id":"RIO7b8GjAC17"},"outputs":[],"source":["corpus = np.array(['que dia es hoy', 'martes el dia de hoy es martes', 'martes muchas gracias'])"]},{"cell_type":"markdown","metadata":{"id":"8WqdaTmO8P1r"},"source":["Documento 1 --> que dia es hoy \\\n","Documento 2 --> martes el dia de hoy es martes \\\n","Documento 3 --> martes muchas gracias"]},{"cell_type":"markdown","metadata":{"id":"FVHxBRNzCMOS"},"source":["### 1 - Obtener el vocabulario del corpus (los términos utilizados)\n","- Cada documento transformarlo en una lista de términos\n","- Armar un vector de términos no repetidos de todos los documentos"]},{"cell_type":"code","execution_count":18,"metadata":{"id":"3ZqTOZzDI7uv"},"outputs":[{"data":{"text/plain":["[['que', 'dia', 'es', 'hoy'],\n"," ['martes', 'el', 'dia', 'de', 'hoy', 'es', 'martes'],\n"," ['martes', 'muchas', 'gracias']]"]},"execution_count":18,"metadata":{},"output_type":"execute_result"}],"source":["# obtenemos tamaño del corpus\n","corpus_size = len(corpus)\n","document_list = []\n","\n","# buscamos documentos y dividimos en terminos\n","for i in range(corpus_size):\n","    document = corpus[i].split()\n","    document_list.append(document)\n","\n","document_list"]},{"cell_type":"code","execution_count":19,"metadata":{},"outputs":[{"data":{"text/plain":["array(['que', 'dia', 'es', 'hoy', 'martes', 'el', 'dia', 'de', 'hoy',\n","       'es', 'martes', 'martes', 'muchas', 'gracias'], dtype='<U7')"]},"execution_count":19,"metadata":{},"output_type":"execute_result"}],"source":["# unimos listas\n","merge_list = np.concatenate(document_list).ravel()\n","merge_list"]},{"cell_type":"code","execution_count":21,"metadata":{},"outputs":[{"name":"stdout","output_type":"stream","text":[" vocabulario: ['que', 'dia', 'es', 'hoy', 'martes', 'el', 'de', 'muchas', 'gracias']\n"]}],"source":["# obtenemos vocabulario\n","vocabulary = []\n","[vocabulary.append(term) for term in merge_list if term not in vocabulary]\n","print(f\" vocabulario: {vocabulary}\")"]},{"cell_type":"code","execution_count":22,"metadata":{},"outputs":[],"source":["# lo hacemos una función\n","def extract_vocabulary(corpus):\n","    # obtenemos tamaño del corpus\n","    corpus_size = len(corpus)\n","    document_list = []\n","\n","    # buscamos documentos y dividimos en terminos\n","    for i in range(corpus_size):\n","        document = corpus[i].split() \n","        document_list.append(document)\n","    \n","    # unimos listas\n","    merge_list = np.concatenate(document_list).ravel()\n","\n","    # obtenemos vocabulario\n","    vocabulary = []\n","    [vocabulary.append(term) for term in merge_list if term not in vocabulary]\n","\n","    return vocabulary"]},{"cell_type":"code","execution_count":23,"metadata":{},"outputs":[{"name":"stdout","output_type":"stream","text":[" vocabulario: ['que', 'dia', 'es', 'hoy', 'martes', 'el', 'de', 'muchas', 'gracias']\n"]}],"source":["# Probamos función\n","final_result = extract_vocabulary(corpus)\n","print(f\" vocabulario: {final_result}\")"]},{"cell_type":"markdown","metadata":{"id":"RUhH983FI7It"},"source":["### 2- OneHot encoding\n","Data una lista de textos, devolver una matriz con la representación oneHotEncoding de estos"]},{"cell_type":"code","execution_count":43,"metadata":{},"outputs":[],"source":["# creamos un nuevo corpus\n","corpus_2 = np.array(['como esta el dia', 'el dia de hoy esta calido', 'calido como en el caribe'])"]},{"cell_type":"code","execution_count":64,"metadata":{"id":"Os0AAQo6I6Z1"},"outputs":[],"source":["# creamos función para el OneHotEncoding\n","def oneHotEncoding(corpus):\n","    # extraemos vocabulario\n","    vocabulary_for_ohe = extract_vocabulary(corpus)\n","    print(f\"vocabulario: {vocabulary_for_ohe}\")\n","    # inicializamos variables\n","    corpus_size = len(corpus)\n","    ohe_matriz = []\n","    # calculamos vector\n","    for i in range(corpus_size):\n","        # buscamos documento y dividimos en terminos\n","        document = corpus[i].split()\n","        print(f\"documento: {document}\")\n","        ohe_vector = []\n","\n","        # revisamos si el termino en el vocabulario existe en un docu\n","        for term in vocabulary_for_ohe:\n","            if term not in document:\n","                ohe_vector.append(0) # si no existe colocamos 0\n","            else:\n","                ohe_vector.append(1) # si existe colocamos 1\n","\n","        # acumulamos los vectores por documento revisado\n","        ohe_matriz.append(ohe_vector)\n","\n","    return np.array(ohe_matriz)"]},{"cell_type":"code","execution_count":65,"metadata":{},"outputs":[{"name":"stdout","output_type":"stream","text":["vocabulario: ['como', 'esta', 'el', 'dia', 'de', 'hoy', 'calido', 'en', 'caribe']\n","documento: ['como', 'esta', 'el', 'dia']\n","documento: ['el', 'dia', 'de', 'hoy', 'esta', 'calido']\n","documento: ['calido', 'como', 'en', 'el', 'caribe']\n"]},{"data":{"text/plain":["array([[1, 1, 1, 1, 0, 0, 0, 0, 0],\n","       [0, 1, 1, 1, 1, 1, 1, 0, 0],\n","       [1, 0, 1, 0, 0, 0, 1, 1, 1]])"]},"execution_count":65,"metadata":{},"output_type":"execute_result"}],"source":["ohe = oneHotEncoding(corpus_2)\n","ohe"]},{"cell_type":"code","execution_count":66,"metadata":{},"outputs":[{"name":"stdout","output_type":"stream","text":["vocabulario: ['que', 'dia', 'es', 'hoy', 'martes', 'el', 'de', 'muchas', 'gracias']\n","documento: ['que', 'dia', 'es', 'hoy']\n","documento: ['martes', 'el', 'dia', 'de', 'hoy', 'es', 'martes']\n","documento: ['martes', 'muchas', 'gracias']\n"]},{"data":{"text/plain":["array([[1, 1, 1, 1, 0, 0, 0, 0, 0],\n","       [0, 1, 1, 1, 1, 1, 1, 0, 0],\n","       [0, 0, 0, 0, 1, 0, 0, 1, 1]])"]},"execution_count":66,"metadata":{},"output_type":"execute_result"}],"source":["# probamos con corpus original\n","ohe_2 = oneHotEncoding(corpus)\n","ohe_2"]},{"cell_type":"markdown","metadata":{"id":"IIyWGmCpJVQL"},"source":["### 3- Vectores de frecuencia\n","Data una lista de textos, devolver una matriz con la representación de frecuencia de estos"]},{"cell_type":"code","execution_count":67,"metadata":{"id":"yqij_7eHJbUi"},"outputs":[],"source":["def frecVector(corpus):\n","    # extraemos vocabulario\n","    vocabulary_for_vecfr = extract_vocabulary(corpus)\n","    print(f\"vocabulario: {vocabulary_for_vecfr}\")\n","    # inicializamos variables\n","    corpus_size = len(corpus)\n","    vecfr_matriz = []\n","    # calculamos vector\n","    for i in range(corpus_size):\n","        # buscamos documento y dividimos en terminos\n","        document = corpus[i].split()\n","        print(f\"documento: {document}\")\n","        vector = []\n","\n","        # revisamos si el termino en el vocabulario existe en un docu\n","        for term in vocabulary_for_vecfr:\n","            if term not in document:\n","                vector.append(0) # si no existe colocamos 0\n","            else:\n","                # buscamos cuantas veces se repite el termino en el documento\n","                num_obs = len([count for count, value in enumerate(document) if value == term])\n","                vector.append(num_obs)\n","\n","        # acumulamos los vectores por documento revisado\n","        vecfr_matriz.append(vector)\n","\n","    return np.array(vecfr_matriz)"]},{"cell_type":"code","execution_count":68,"metadata":{},"outputs":[{"name":"stdout","output_type":"stream","text":["vocabulario: ['que', 'dia', 'es', 'hoy', 'martes', 'el', 'de', 'muchas', 'gracias']\n","documento: ['que', 'dia', 'es', 'hoy']\n","documento: ['martes', 'el', 'dia', 'de', 'hoy', 'es', 'martes']\n","documento: ['martes', 'muchas', 'gracias']\n"]},{"data":{"text/plain":["array([[1, 1, 1, 1, 0, 0, 0, 0, 0],\n","       [0, 1, 1, 1, 2, 1, 1, 0, 0],\n","       [0, 0, 0, 0, 1, 0, 0, 1, 1]])"]},"execution_count":68,"metadata":{},"output_type":"execute_result"}],"source":["# probamos con corpus original\n","vecfr = frecVector(corpus)\n","vecfr"]},{"cell_type":"code","execution_count":69,"metadata":{},"outputs":[{"name":"stdout","output_type":"stream","text":["vocabulario: ['que', 'bueno', 'esta', 'muy', 'excelente']\n","documento: ['que', 'bueno', 'que', 'esta']\n","documento: ['esta', 'muy', 'bueno']\n","documento: ['esta', 'excelente']\n"]},{"data":{"text/plain":["array([[2, 1, 1, 0, 0],\n","       [0, 1, 1, 1, 0],\n","       [0, 0, 1, 0, 1]])"]},"execution_count":69,"metadata":{},"output_type":"execute_result"}],"source":["# Probamos otro corpus\n","corpus_3 = np.array(['que bueno que esta', 'esta muy bueno', 'esta excelente'])\n","\n","vecfr_2 = frecVector(corpus_3)\n","vecfr_2"]},{"cell_type":"markdown","metadata":{"id":"z_Ot8HvWJcBu"},"source":["### 4- TF-IDF\n","Data una lista de textos, devolver una matriz con la representacion TFIDF"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"waG_oWtpJjRw"},"outputs":[],"source":[]},{"cell_type":"markdown","metadata":{"id":"xMcsfndWJjm_"},"source":["### 5 - Comparación de documentos\n","Realizar una funcion que reciba el corpus y el índice de un documento y devuelva los documentos ordenados por la similitud coseno"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"CZdiop6IJpZN"},"outputs":[],"source":[]}],"metadata":{"colab":{"authorship_tag":"ABX9TyO5fRYTpympAwJSVbric6dW","collapsed_sections":[],"name":"1a - word2vec.ipynb","provenance":[]},"kernelspec":{"display_name":"Python 3","name":"python3"},"language_info":{"codemirror_mode":{"name":"ipython","version":3},"file_extension":".py","mimetype":"text/x-python","name":"python","nbconvert_exporter":"python","pygments_lexer":"ipython3","version":"3.10.9"}},"nbformat":4,"nbformat_minor":0}
