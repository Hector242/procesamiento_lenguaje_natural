{"cells":[{"attachments":{},"cell_type":"markdown","metadata":{"id":"Ue5hxxkdAQJg"},"source":["<img src=\"https://github.com/FIUBA-Posgrado-Inteligencia-Artificial/procesamiento_lenguaje_natural/raw/main/logoFIUBA.jpg\" width=\"500\" align=\"center\">\n","\n","\n","# Procesamiento de lenguaje natural\n","## Vectorización\n"]},{"cell_type":"code","execution_count":392,"metadata":{"id":"kCED1hh-Ioyf"},"outputs":[],"source":["import numpy as np"]},{"cell_type":"code","execution_count":393,"metadata":{"id":"PUbfVnzIIoMj"},"outputs":[],"source":["def cosine_similarity(a, b):\n","    return np.dot(a, b) / (np.linalg.norm(a) * (np.linalg.norm(b)))"]},{"cell_type":"markdown","metadata":{"id":"DMOa4JPSCJ29"},"source":["### Datos"]},{"cell_type":"code","execution_count":394,"metadata":{"id":"RIO7b8GjAC17"},"outputs":[],"source":["corpus = np.array(['que dia es hoy', 'martes el dia de hoy es martes', 'martes muchas gracias'])"]},{"cell_type":"markdown","metadata":{"id":"8WqdaTmO8P1r"},"source":["Documento 1 --> que dia es hoy \\\n","Documento 2 --> martes el dia de hoy es martes \\\n","Documento 3 --> martes muchas gracias"]},{"cell_type":"markdown","metadata":{"id":"FVHxBRNzCMOS"},"source":["### 1 - Obtener el vocabulario del corpus (los términos utilizados)\n","- Cada documento transformarlo en una lista de términos\n","- Armar un vector de términos no repetidos de todos los documentos"]},{"cell_type":"code","execution_count":395,"metadata":{"id":"3ZqTOZzDI7uv"},"outputs":[{"data":{"text/plain":["[['que', 'dia', 'es', 'hoy'],\n"," ['martes', 'el', 'dia', 'de', 'hoy', 'es', 'martes'],\n"," ['martes', 'muchas', 'gracias']]"]},"execution_count":395,"metadata":{},"output_type":"execute_result"}],"source":["# obtenemos tamaño del corpus\n","corpus_size = len(corpus)\n","document_list = []\n","\n","# buscamos documentos y dividimos en terminos\n","for i in range(corpus_size):\n","    document = corpus[i].split()\n","    document_list.append(document)\n","\n","document_list"]},{"cell_type":"code","execution_count":396,"metadata":{},"outputs":[{"data":{"text/plain":["array(['que', 'dia', 'es', 'hoy', 'martes', 'el', 'dia', 'de', 'hoy',\n","       'es', 'martes', 'martes', 'muchas', 'gracias'], dtype='<U7')"]},"execution_count":396,"metadata":{},"output_type":"execute_result"}],"source":["# unimos listas\n","merge_list = np.concatenate(document_list).ravel()\n","merge_list"]},{"cell_type":"code","execution_count":397,"metadata":{},"outputs":[{"name":"stdout","output_type":"stream","text":[" vocabulario: ['que', 'dia', 'es', 'hoy', 'martes', 'el', 'de', 'muchas', 'gracias']\n"]}],"source":["# obtenemos vocabulario\n","vocabulary = []\n","[vocabulary.append(term) for term in merge_list if term not in vocabulary]\n","print(f\" vocabulario: {vocabulary}\")"]},{"cell_type":"code","execution_count":398,"metadata":{},"outputs":[],"source":["# lo hacemos una función\n","def extract_vocabulary(corpus):\n","    # obtenemos tamaño del corpus\n","    corpus_size = len(corpus)\n","    document_list = []\n","\n","    # buscamos documentos y dividimos en terminos\n","    for i in range(corpus_size):\n","        corpus[i] = np.char.lower(corpus[i]) # pasamos documento a minuscula\n","        document = corpus[i].split() \n","        document_list.append(document)\n","    \n","    # unimos listas\n","    merge_list = np.concatenate(document_list).ravel()\n","\n","    # obtenemos vocabulario\n","    vocabulary = []\n","    [vocabulary.append(term) for term in merge_list if term not in vocabulary]\n","\n","    return vocabulary"]},{"cell_type":"code","execution_count":399,"metadata":{},"outputs":[{"name":"stdout","output_type":"stream","text":[" vocabulario: ['que', 'dia', 'es', 'hoy', 'martes', 'el', 'de', 'muchas', 'gracias']\n"]}],"source":["# Probamos función\n","final_result = extract_vocabulary(corpus)\n","print(f\" vocabulario: {final_result}\")"]},{"cell_type":"markdown","metadata":{"id":"RUhH983FI7It"},"source":["### 2- OneHot encoding\n","Data una lista de textos, devolver una matriz con la representación oneHotEncoding de estos"]},{"cell_type":"code","execution_count":400,"metadata":{"id":"Os0AAQo6I6Z1"},"outputs":[],"source":["# creamos función para el OneHotEncoding\n","def oneHotEncoding(corpus):\n","    # extraemos vocabulario\n","    vocabulary_for_ohe = extract_vocabulary(corpus)\n","    print(f\"vocabulario: {vocabulary_for_ohe}\")\n","    # inicializamos variables\n","    corpus_size = len(corpus)\n","    ohe_matriz = []\n","    # calculamos vector\n","    for i in range(corpus_size):\n","        # buscamos documento y dividimos en terminos\n","        document = corpus[i].split()\n","        print(f\"documento{i+1}: {document}\")\n","        ohe_vector = []\n","\n","        # revisamos si el termino en el vocabulario existe en un docu\n","        for term in vocabulary_for_ohe:\n","            if term not in document:\n","                ohe_vector.append(0) # si no existe colocamos 0\n","            else:\n","                ohe_vector.append(1) # si existe colocamos 1\n","\n","        # acumulamos los vectores por documento revisado\n","        ohe_matriz.append(ohe_vector)\n","\n","    return np.array(ohe_matriz)"]},{"cell_type":"code","execution_count":401,"metadata":{},"outputs":[{"name":"stdout","output_type":"stream","text":["vocabulario: ['que', 'dia', 'es', 'hoy', 'martes', 'el', 'de', 'muchas', 'gracias']\n","documento1: ['que', 'dia', 'es', 'hoy']\n","documento2: ['martes', 'el', 'dia', 'de', 'hoy', 'es', 'martes']\n","documento3: ['martes', 'muchas', 'gracias']\n"]},{"data":{"text/plain":["array([[1, 1, 1, 1, 0, 0, 0, 0, 0],\n","       [0, 1, 1, 1, 1, 1, 1, 0, 0],\n","       [0, 0, 0, 0, 1, 0, 0, 1, 1]])"]},"execution_count":401,"metadata":{},"output_type":"execute_result"}],"source":["oneHotEncoding(corpus)"]},{"cell_type":"markdown","metadata":{"id":"IIyWGmCpJVQL"},"source":["### 3- Vectores de frecuencia\n","Data una lista de textos, devolver una matriz con la representación de frecuencia de estos"]},{"cell_type":"code","execution_count":402,"metadata":{"id":"yqij_7eHJbUi"},"outputs":[],"source":["def frecVector(corpus):\n","    # extraemos vocabulario\n","    vocabulary_for_vecfr = extract_vocabulary(corpus)\n","    print(f\"vocabulario: {vocabulary_for_vecfr}\")\n","    # inicializamos variables\n","    corpus_size = len(corpus)\n","    vecfr_matriz = []\n","    # calculamos vector\n","    for i in range(corpus_size):\n","        # buscamos documento y dividimos en terminos\n","        document = corpus[i].split()\n","        print(f\"documento{i+1}: {document}\")\n","        vector = []\n","\n","        # revisamos si el termino en el vocabulario existe en un docu\n","        for term in vocabulary_for_vecfr:\n","            if term not in document:\n","                vector.append(0) # si no existe colocamos 0\n","            else:\n","                # buscamos cuantas veces se repite el termino en el documento\n","                num_obs = len([count for count, value in enumerate(document) if value == term])\n","                vector.append(num_obs)\n","\n","        # acumulamos los vectores por documento revisado\n","        vecfr_matriz.append(vector)\n","\n","    return np.array(vecfr_matriz)"]},{"cell_type":"code","execution_count":403,"metadata":{},"outputs":[{"name":"stdout","output_type":"stream","text":["vocabulario: ['que', 'dia', 'es', 'hoy', 'martes', 'el', 'de', 'muchas', 'gracias']\n","documento1: ['que', 'dia', 'es', 'hoy']\n","documento2: ['martes', 'el', 'dia', 'de', 'hoy', 'es', 'martes']\n","documento3: ['martes', 'muchas', 'gracias']\n"]},{"data":{"text/plain":["array([[1, 1, 1, 1, 0, 0, 0, 0, 0],\n","       [0, 1, 1, 1, 2, 1, 1, 0, 0],\n","       [0, 0, 0, 0, 1, 0, 0, 1, 1]])"]},"execution_count":403,"metadata":{},"output_type":"execute_result"}],"source":["frecVector(corpus)"]},{"cell_type":"markdown","metadata":{"id":"z_Ot8HvWJcBu"},"source":["### 4- TF-IDF\n","Data una lista de textos, devolver una matriz con la representacion TFIDF"]},{"cell_type":"code","execution_count":404,"metadata":{"id":"waG_oWtpJjRw"},"outputs":[],"source":["from math import log\n","\n","def tf_idf(corpus):\n","    # extraemos vocabulario\n","    vocabulary_for_tfidf = extract_vocabulary(corpus)\n","    print(f\"vocabulario: {vocabulary_for_tfidf}\")\n","    # inicializamos variables\n","    corpus_size = len(corpus)\n","    tfidf_matriz = []\n","        \n","    # calculamos vector\n","    for i in range(corpus_size):\n","        # buscamos documento y dividimos en terminos\n","        document = corpus[i].split()\n","        print(f\"documento{i+1}: {document}\")\n","        vector = []\n","        idf_terms = []\n","        # revision en vocabulario\n","        for term in vocabulary_for_tfidf:\n","            # IDF\n","            [idf_terms.append(term) for doc in corpus if term in doc] \n","            idf_values = len([count for count, value in enumerate(idf_terms) if value == term])\n","            idf = log(corpus_size / idf_values)\n","            # TF-IDF\n","            if term not in document:\n","                vector.append(0 * idf) # si no existe colocamos 0\n","            else:\n","                # buscamos cuantas veces se repite el termino en el documento\n","                num_obs = len([count for count, value in enumerate(document) if value == term])\n","                vector.append(num_obs * idf)\n","        \n","        # acumulamos los vectores por documento revisado\n","        tfidf_matriz.append(vector)\n","    \n","\n","    return np.array(tfidf_matriz)"]},{"cell_type":"code","execution_count":405,"metadata":{},"outputs":[{"name":"stdout","output_type":"stream","text":["vocabulario: ['que', 'dia', 'es', 'hoy', 'martes', 'el', 'de', 'muchas', 'gracias']\n","documento1: ['que', 'dia', 'es', 'hoy']\n","documento2: ['martes', 'el', 'dia', 'de', 'hoy', 'es', 'martes']\n","documento3: ['martes', 'muchas', 'gracias']\n"]},{"data":{"text/plain":["array([[1.09861229, 0.40546511, 0.        , 0.40546511, 0.        ,\n","        0.        , 0.        , 0.        , 0.        ],\n","       [0.        , 0.40546511, 0.        , 0.40546511, 0.81093022,\n","        1.09861229, 1.09861229, 0.        , 0.        ],\n","       [0.        , 0.        , 0.        , 0.        , 0.40546511,\n","        0.        , 0.        , 1.09861229, 1.09861229]])"]},"execution_count":405,"metadata":{},"output_type":"execute_result"}],"source":["tf_idf(corpus)"]},{"cell_type":"markdown","metadata":{"id":"xMcsfndWJjm_"},"source":["### 5 - Comparación de documentos\n","Realizar una funcion que reciba el corpus y el índice de un documento y devuelva los documentos ordenados por la similitud coseno"]},{"cell_type":"code","execution_count":406,"metadata":{"id":"CZdiop6IJpZN"},"outputs":[],"source":["# comparamos documentos con OneHotEncoder\n","def compare_doc_ohe(corpus, idx):\n","    # vectorizamos\n","    ohe_matrix = oneHotEncoding(corpus)\n","    target_vector = ohe_matrix[idx]\n","    # similitud del coseno\n","    cos_sim = [cosine_similarity(target_vector, vector) for vector in ohe_matrix]\n","    print(f\"Similitud del coseno: {cos_sim}\")\n","    \n","    # ordenando los documentos de mayor coincidencia a menor\n","    sort_idx = np.argsort(cos_sim)[::-1]\n","    document_ord = [corpus[i] for i in sort_idx]\n","\n","    return document_ord"]},{"cell_type":"code","execution_count":407,"metadata":{},"outputs":[{"name":"stdout","output_type":"stream","text":["vocabulario: ['que', 'dia', 'es', 'hoy', 'martes', 'el', 'de', 'muchas', 'gracias']\n","documento1: ['que', 'dia', 'es', 'hoy']\n","documento2: ['martes', 'el', 'dia', 'de', 'hoy', 'es', 'martes']\n","documento3: ['martes', 'muchas', 'gracias']\n","Similitud del coseno: [0.6123724356957946, 1.0000000000000002, 0.23570226039551587]\n","\n","ordenando los documentos de mayor coincidencia a menor:\n","['martes el dia de hoy es martes', 'que dia es hoy', 'martes muchas gracias']\n"]}],"source":["doc_compared = compare_doc_ohe(corpus, 1)\n","print(f\"\\nordenando los documentos de mayor coincidencia a menor:\\n{doc_compared}\")"]},{"cell_type":"code","execution_count":408,"metadata":{},"outputs":[],"source":["# comparamos documentos con vector de frecuencia\n","def compare_doc_vrf(corpus, idx):\n","    # vectorizamos\n","    vfr_matrix = frecVector(corpus)\n","    target_vector = vfr_matrix[idx]\n","    # similitud del coseno\n","    cos_sim = [cosine_similarity(target_vector, vector) for vector in vfr_matrix]\n","    print(f\"Similitud del coseno: {cos_sim}\")\n","    \n","    # ordenando los documentos de mayor coincidencia a menor\n","    sort_idx = np.argsort(cos_sim)[::-1]\n","    document_ord = [corpus[i] for i in sort_idx]\n","\n","    return document_ord"]},{"cell_type":"code","execution_count":409,"metadata":{},"outputs":[{"name":"stdout","output_type":"stream","text":["vocabulario: ['que', 'dia', 'es', 'hoy', 'martes', 'el', 'de', 'muchas', 'gracias']\n","documento1: ['que', 'dia', 'es', 'hoy']\n","documento2: ['martes', 'el', 'dia', 'de', 'hoy', 'es', 'martes']\n","documento3: ['martes', 'muchas', 'gracias']\n","Similitud del coseno: [0.5, 1.0, 0.3849001794597505]\n","\n","ordenando los documentos de mayor coincidencia a menor:\n","['martes el dia de hoy es martes', 'que dia es hoy', 'martes muchas gracias']\n"]}],"source":["doc_compared_2 = compare_doc_vrf(corpus, 1)\n","print(f\"\\nordenando los documentos de mayor coincidencia a menor:\\n{doc_compared_2}\")"]},{"cell_type":"code","execution_count":410,"metadata":{},"outputs":[],"source":["# comparamos documentos con TF-IDF\n","def compare_doc_tfidf(corpus, idx):\n","    # vectorizamos\n","    tf_idf_matrix = tf_idf(corpus)\n","    target_vector = tf_idf_matrix[idx]\n","    # similitud del coseno\n","    cos_sim = [cosine_similarity(target_vector, vector) for vector in tf_idf_matrix]\n","    print(f\"Similitud del coseno: {cos_sim}\")\n","    \n","    # ordenando los documentos de mayor coincidencia a menor\n","    sort_idx = np.argsort(cos_sim)[::-1]\n","    document_ord = [corpus[i] for i in sort_idx]\n","\n","    return document_ord"]},{"cell_type":"code","execution_count":411,"metadata":{},"outputs":[{"name":"stdout","output_type":"stream","text":["vocabulario: ['que', 'dia', 'es', 'hoy', 'martes', 'el', 'de', 'muchas', 'gracias']\n","documento1: ['que', 'dia', 'es', 'hoy']\n","documento2: ['martes', 'el', 'dia', 'de', 'hoy', 'es', 'martes']\n","documento3: ['martes', 'muchas', 'gracias']\n","Similitud del coseno: [0.14388551287405218, 0.9999999999999999, 0.1110480720364697]\n","\n","ordenando los documentos de mayor coincidencia a menor:\n","['martes el dia de hoy es martes', 'que dia es hoy', 'martes muchas gracias']\n"]}],"source":["doc_compared_3 = compare_doc_tfidf(corpus, 1)\n","print(f\"\\nordenando los documentos de mayor coincidencia a menor:\\n{doc_compared_3}\")"]},{"cell_type":"markdown","metadata":{},"source":["**Analisis**\n","\n","Vectorizando y comparando los documentos entre si con la similitud del coseno, se puede observar que los resultados son muy similares, sin importar la vectorización que se utilice. Es decir, al buscar la coincidencia de un documento en un corpus usando la similitud del coseno, podemos encontrar el documento que más coincide sin importar con que se vectoriza. Sin embargo, dependiendo del metodo que se utilice para vectorizar, los valores de la similitud del coseno varían, pero mantienen las mismas coincidencias según se puede observar en las pruebas anteriores.\n","\n","Recordando que mientras más cercano sea este valor a 1 significa que la coincidencia es mayor entre documentos y mientras más cercano es a 0 es el caso contrario."]}],"metadata":{"colab":{"authorship_tag":"ABX9TyO5fRYTpympAwJSVbric6dW","collapsed_sections":[],"name":"1a - word2vec.ipynb","provenance":[]},"kernelspec":{"display_name":"Python 3","name":"python3"},"language_info":{"codemirror_mode":{"name":"ipython","version":3},"file_extension":".py","mimetype":"text/x-python","name":"python","nbconvert_exporter":"python","pygments_lexer":"ipython3","version":"3.10.9"}},"nbformat":4,"nbformat_minor":0}
